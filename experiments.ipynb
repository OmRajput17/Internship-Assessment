{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9ee1f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db6feb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c90235a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001E6C516C710>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001E6C54B5D50>, model_name='openai/gpt-oss-20b', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model = \"openai/gpt-oss-20b\", groq_api_key = groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7300516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey there! I’m ChatGPT, an AI language model created by OpenAI. I’m here to help answer questions, brainstorm ideas, explain concepts, or just chat about whatever’s on your mind. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(\"Hey! Who are you?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c829ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Machine Learning (ML)** is a branch of computer science and artificial intelligence that gives computers the ability to learn from data, identify patterns, and make decisions with minimal human intervention.\n",
      "\n",
      "### Core idea\n",
      "- **Data + Algorithms → Model**: An algorithm processes input data, adjusts internal parameters, and produces a model that can predict or classify new, unseen data.\n",
      "- **Learning**: The model improves its performance as it sees more data or receives feedback on its predictions.\n",
      "\n",
      "### Key components\n",
      "\n",
      "| Component | What it is | Example |\n",
      "|-----------|------------|---------|\n",
      "| **Data** | Raw information (images, text, numbers, etc.) | Thousands of labeled photos of cats and dogs |\n",
      "| **Model** | Mathematical representation of patterns | A neural network with millions of weights |\n",
      "| **Algorithm** | Procedure for training the model | Gradient descent, decision‑tree splitting |\n",
      "| **Loss/Objective** | Measure of error | Cross‑entropy loss for classification |\n",
      "| **Evaluation** | How well the model performs | Accuracy, precision, recall |\n",
      "\n",
      "### Types of Machine Learning\n",
      "\n",
      "| Type | How it works | Typical use cases |\n",
      "|------|--------------|-------------------|\n",
      "| **Supervised** | Learns from labeled examples (input → output) | Spam detection, image recognition |\n",
      "| **Unsupervised** | Finds hidden structure in unlabeled data | Clustering customers, anomaly detection |\n",
      "| **Semi‑supervised** | Combines a small amount of labeled data with a large amount of unlabeled data | Speech recognition with limited transcriptions |\n",
      "| **Reinforcement** | Learns by interacting with an environment and receiving rewards | Game playing, robotics control |\n",
      "\n",
      "### The learning cycle\n",
      "\n",
      "1. **Collect data** → 2. **Preprocess** (clean, normalize) → 3. **Choose a model** → 4. **Train** (adjust parameters to minimize loss) → 5. **Validate** (test on unseen data) → 6. **Deploy** (use in real applications) → 7. **Monitor & update** (re‑train as needed)\n",
      "\n",
      "### Why it matters\n",
      "\n",
      "- **Automation**: Replaces manual rules with data‑driven decisions.\n",
      "- **Scalability**: Handles vast amounts of data that would be impossible for humans to process manually.\n",
      "- **Adaptability**: Models can be retrained to reflect new patterns or changes in the environment.\n",
      "\n",
      "In short, **machine learning lets computers learn from experience, improve over time, and perform tasks that traditionally required human intelligence.**\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(\"What is Machine Learning?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3eba24c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = 'true'\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe3bd5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\" , \"Hey! You're a helpful Assistant to Answer User's Query to the best. Your name is Saarthi.\"),\n",
    "        (\"human\", \"Question : {question}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fcaf044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(question, api_key):\n",
    "    llm = ChatGroq(\n",
    "        model = \"openai/gpt-oss-20b\", groq_api_key = api_key\n",
    "    )\n",
    "    output_parser = StrOutputParser()\n",
    "    chain = prompt | llm | output_parser\n",
    "    answer = chain.invoke({'question': question })\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6479659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Generative AI** refers to a class of artificial‑intelligence models that can create new content—text, images, audio, video, code, and more—rather than just recognizing or classifying existing data. These models learn patterns and structures from large datasets and then use that knowledge to generate novel outputs that resemble the training data.\n",
      "\n",
      "### Key Characteristics\n",
      "\n",
      "| Feature | Description |\n",
      "|---------|-------------|\n",
      "| **Learning from data** | Trained on vast corpora (e.g., books, websites, images) to capture statistical regularities. |\n",
      "| **Probabilistic generation** | Produces outputs by sampling from learned probability distributions. |\n",
      "| **Versatility** | Can generate text, images, music, 3D models, and even design code or recipes. |\n",
      "| **Conditional generation** | Allows control via prompts or constraints (e.g., “write a poem in the style of Shakespeare”). |\n",
      "| **Feedback loops** | Often refined with human-in-the-loop or reinforcement learning to improve quality. |\n",
      "\n",
      "### Common Generative Models\n",
      "\n",
      "- **Language Models**: GPT‑4, Claude, LLaMA – generate coherent text, answer questions, compose stories.\n",
      "- **Image Models**: DALL·E, Midjourney, Stable Diffusion – create realistic or stylized images from textual prompts.\n",
      "- **Audio Models**: Jukebox, AudioLM – generate music or speech.\n",
      "- **Multimodal Models**: Gemini, GPT‑4V – understand and produce across text, image, and other modalities.\n",
      "\n",
      "### How They Work (Simplified)\n",
      "\n",
      "1. **Training**: The model is exposed to a huge dataset and learns to predict the next element (word, pixel, etc.) in a sequence.\n",
      "2. **Inference**: Given a prompt, the model samples from its learned distribution to produce new content.\n",
      "3. **Post‑processing**: Outputs may be refined or filtered for quality, safety, or style.\n",
      "\n",
      "### Applications\n",
      "\n",
      "- Creative content creation (stories, art, music)\n",
      "- Design and prototyping (fashion, architecture)\n",
      "- Code generation and debugging\n",
      "- Personalized marketing and copywriting\n",
      "- Simulation and training (virtual environments)\n",
      "- Assistive tools for education and accessibility\n",
      "\n",
      "### Ethical & Safety Considerations\n",
      "\n",
      "- **Bias & Fairness**: Models can reproduce societal biases present in training data.\n",
      "- **Plagiarism & Attribution**: Generated content may inadvertently echo copyrighted material.\n",
      "- **Misinformation**: High‑quality fake text or media can be used maliciously.\n",
      "- **Economic Impact**: Automation of creative tasks may affect jobs.\n",
      "\n",
      "### Bottom Line\n",
      "\n",
      "Generative AI is a powerful technology that moves beyond mere data analysis to **creating** new, original content. Its rapid advancement is reshaping industries, but it also demands careful governance to address ethical, legal, and societal challenges.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"What is Generative AI?\"\n",
    "\n",
    "if user_input:\n",
    "    response = generate_response(question=user_input, api_key=groq_api_key)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6b9aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
